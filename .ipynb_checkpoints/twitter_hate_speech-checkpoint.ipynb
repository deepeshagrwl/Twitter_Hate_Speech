{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\deepeshag\\\\Downloads\\\\Analytics Vidhya'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from string import punctuation\n",
    "import re\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test_tweets.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "id                                                          \n",
       "1       0   @user when a father is dysfunctional and is s...\n",
       "2       0  @user @user thanks for #lyft credit i can't us...\n",
       "3       0                                bihday your majesty\n",
       "4       0  #model   i love u take with u all the time in ...\n",
       "5       0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.set_index('id', inplace = True)\n",
    "test.set_index('id', inplace = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "catg = train.groupby('label')\n",
    "fig, ax = plt.subplots()\n",
    "categories = ['Positive','Negative']\n",
    "ax.bar(categories,catg.count().unstack())\n",
    "ax.text(0, catg.count().unstack()[0], catg.count().unstack()[0], ha='center', va='bottom')\n",
    "ax.text(1, catg.count().unstack()[1], catg.count().unstack()[1], ha='center', va='bottom')\n",
    "plt.show()\n",
    "ratio = catg.count().unstack()[0]/(catg.count().unstack()[1]+catg.count().unstack()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=SnowballStemmer('english', ignore_stopwords = True)\n",
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review_col, stem = False):\n",
    "    review_corpus=[]\n",
    "    for i in range(0,len(review_col)):\n",
    "        review=str(review_col[i])\n",
    "        ##Remove User Name, Special Characters, URL's & whitespaces\n",
    "        review=re.sub(\"@\\S+|[^A-Za-z0-9@']+|https?:\\S+|http?:\\S+\",' ',review).strip()\n",
    "        review_corpus.append(review)\n",
    "    return review_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i can't use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet  \\\n",
       "id                                                             \n",
       "1       0   @user when a father is dysfunctional and is s...   \n",
       "2       0  @user @user thanks for #lyft credit i can't us...   \n",
       "3       0                                bihday your majesty   \n",
       "4       0  #model   i love u take with u all the time in ...   \n",
       "5       0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          clean_tweet  \n",
       "id                                                     \n",
       "1   when a father is dysfunctional and is so selfi...  \n",
       "2   thanks for lyft credit i can't use cause they ...  \n",
       "3                                 bihday your majesty  \n",
       "4       model i love u take with u all the time in ur  \n",
       "5                   factsguide society now motivation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_tweet'] = clean_review(train.tweet.values)\n",
    "test['clean_tweet'] = clean_review(test.tweet.values)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(review_col):\n",
    "    token_corpus = []\n",
    "    for i in range(0,len(review_col)):\n",
    "        text=str(review_col[i])\n",
    "        tokens = []\n",
    "        for token in text.split():\n",
    "            tokens.append(stemmer.stem(token))\n",
    "            x = \" \".join(tokens)\n",
    "        token_corpus.append(x)\n",
    "    return token_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunct and is so selfish he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i can't use cause they ...</td>\n",
       "      <td>thank for lyft credit i can't use caus they do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>factsguid societi now motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet  \\\n",
       "id                                                             \n",
       "1       0   @user when a father is dysfunctional and is s...   \n",
       "2       0  @user @user thanks for #lyft credit i can't us...   \n",
       "3       0                                bihday your majesty   \n",
       "4       0  #model   i love u take with u all the time in ...   \n",
       "5       0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          clean_tweet  \\\n",
       "id                                                      \n",
       "1   when a father is dysfunctional and is so selfi...   \n",
       "2   thanks for lyft credit i can't use cause they ...   \n",
       "3                                 bihday your majesty   \n",
       "4       model i love u take with u all the time in ur   \n",
       "5                   factsguide society now motivation   \n",
       "\n",
       "                                        stemmed_tweet  \n",
       "id                                                     \n",
       "1   when a father is dysfunct and is so selfish he...  \n",
       "2   thank for lyft credit i can't use caus they do...  \n",
       "3                                 bihday your majesti  \n",
       "4       model i love u take with u all the time in ur  \n",
       "5                         factsguid societi now motiv  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['stemmed_tweet'] = stemming(train.clean_tweet.values)\n",
    "test['stemmed_tweet'] = stemming(test.clean_tweet.values)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 30363\n",
      "Validation size: 1599\n",
      "Test size: 17197\n"
     ]
    }
   ],
   "source": [
    "df_train, df_validation = train_test_split(train, test_size=0.05, random_state=1)\n",
    "print(\"Train size:\", len(df_train))\n",
    "print(\"Validation size:\", len(df_validation))\n",
    "print(\"Test size:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in range(0,len(df_train.stemmed_tweet)):\n",
    "    document = []\n",
    "    txt = df_train.stemmed_tweet.iloc[i]\n",
    "    txt_split = txt.split()\n",
    "    for x in txt_split:\n",
    "        document.append(x)\n",
    "    docs.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=300, window=7, min_count=10, workers=8)\n",
    "w2v_model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 3183\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab = len(words)\n",
    "print(\"Vocab size\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8297051, 12005792)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(docs, total_examples=len(docs), epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('zen', 0.475773423910141),\n",
       " ('belief', 0.45173409581184387),\n",
       " ('quoteoftheday', 0.4390312433242798),\n",
       " ('enjoylif', 0.4379325807094574),\n",
       " ('selflov', 0.432190477848053),\n",
       " ('medit', 0.43050408363342285),\n",
       " ('daili', 0.43027931451797485),\n",
       " ('wednesdaywisdom', 0.4202378988265991),\n",
       " ('optimist', 0.41935986280441284),\n",
       " ('goodmood', 0.4170556664466858)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"posit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 32119\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.stemmed_tweet)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.stemmed_tweet), maxlen=300)\n",
    "x_validation = pad_sequences(tokenizer.texts_to_sequences(df_validation.stemmed_tweet), maxlen=300)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test.stemmed_tweet), maxlen=300)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.label.tolist())\n",
    "y_train = encoder.transform(df_train.label.tolist())\n",
    "y_validation = encoder.transform(df_validation.label.tolist())\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_validation = y_validation.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (30363, 300)\n",
      "y_train (30363, 1)\n",
      "x_validation (1599, 300)\n",
      "y_validation (1599, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_validation\", x_validation.shape)\n",
    "print(\"y_validation\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32119, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 14:49:20.637709 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=300, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:49:27.388010 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 14:49:27.421916 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0805 14:49:27.439872 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0805 14:49:27.441863 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0805 14:49:27.998461 35812 deprecation.py:506] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          9635700   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 9,796,201\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 9,635,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:49:33.923449 35812 deprecation_wrapper.py:119] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 14:49:33.962509 35812 deprecation.py:323] From C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_f1', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27326 samples, validate on 3037 samples\n",
      "Epoch 1/8\n",
      "27326/27326 [==============================] - 469s 17ms/step - loss: 0.3194 - f1: 0.1329 - val_loss: 0.1860 - val_f1: 0.2811\n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepeshag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_f1,loss,f1,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27326/27326 [==============================] - 559s 20ms/step - loss: 0.1725 - f1: 0.3824 - val_loss: 0.1746 - val_f1: 0.3733\n",
      "Epoch 3/8\n",
      "27326/27326 [==============================] - 433s 16ms/step - loss: 0.1593 - f1: 0.4378 - val_loss: 0.1669 - val_f1: 0.4335\n",
      "Epoch 4/8\n",
      "27326/27326 [==============================] - 415s 15ms/step - loss: 0.1528 - f1: 0.4716 - val_loss: 0.1653 - val_f1: 0.4398\n",
      "Epoch 5/8\n",
      "27326/27326 [==============================] - 545s 20ms/step - loss: 0.1483 - f1: 0.4790 - val_loss: 0.1570 - val_f1: 0.4532\n",
      "Epoch 6/8\n",
      "27326/27326 [==============================] - 578s 21ms/step - loss: 0.1433 - f1: 0.4987 - val_loss: 0.1563 - val_f1: 0.4733\n",
      "Epoch 7/8\n",
      "27326/27326 [==============================] - 531s 19ms/step - loss: 0.1386 - f1: 0.5219 - val_loss: 0.1553 - val_f1: 0.4651\n",
      "Epoch 8/8\n",
      "27326/27326 [==============================] - 573s 21ms/step - loss: 0.1360 - f1: 0.5328 - val_loss: 0.1466 - val_f1: 0.5429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=8,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599/1599 [==============================] - 8s 5ms/step\n",
      "\n",
      "ACCURACY: 0.5385432450602843\n",
      "LOSS: 0.1434948166379189\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_validation, y_validation, batch_size=1024)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score):\n",
    "    if score[0] <= 0.3:\n",
    "        label = 0\n",
    "    elif score[0] > 0.3:\n",
    "        label = 1\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_scores = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in predict_scores:\n",
    "    target.append(decode_sentiment(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_sub = pd.DataFrame({'id':test.index.tolist(), 'label':target})\n",
    "samp_sub.to_csv('samp_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
